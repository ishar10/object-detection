{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:207: error: (-212:Parsing error) Failed to parse NetParameter file: yolov3-tiny.cfg in function 'cv::dnn::dnn4_v20201117::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2c3e601cba68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolov3-tiny_last.weights'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yolov3-tiny.cfg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"classes.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:207: error: (-212:Parsing error) Failed to parse NetParameter file: yolov3-tiny.cfg in function 'cv::dnn::dnn4_v20201117::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "net = cv2.dnn.readNet('yolov3-tiny_last.weights', 'yolov3-tiny.cfg')\n",
    "\n",
    "classes = []\n",
    "with open(\"classes.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "img=cv2.imread('test.jpg')\n",
    "height, width, _ = img.shape\n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg.txt')\n",
    "\n",
    "classes = []\n",
    "with open(\"coco.names.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "img=cv2.imread('images.jpg')\n",
    "height, width, _ = img.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "for b in blob:\n",
    "    for n,img_blob in enumerate(b):\n",
    "        cv2.imshow(str(n),img_blob)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[2 1]\n",
      "169 7 89 94\n",
      "51 21 69 76\n"
     ]
    }
   ],
   "source": [
    "net = cv2.dnn.readNet('yolov3_training_last.weights', 'yolov3_testing.cfg')\n",
    "classes = []\n",
    "with open(\"class.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "img=cv2.imread('test_image5.jpg')\n",
    "height, width, _ = img.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "for output in layerOutputs:\n",
    "    #print(len(output[0]))\n",
    "    for detection in output:\n",
    "            \n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "# print(scores)\n",
    "print(class_ids[0])\n",
    "# print(len(boxes))\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "print(indexes.flatten())\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(100, 3))\n",
    "for i in indexes.flatten():\n",
    "    x, y, w, h = boxes[i]\n",
    "    print(x,y,w,h)\n",
    "    label = str(classes[class_ids[i]])\n",
    "    confidence = str(round(confidences[i],2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "\n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3_training_last.weights', 'yolov3_testing.cfg')\n",
    "\n",
    "classes = []\n",
    "with open(\"class.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "cap = cv2.VideoCapture('WhatsApp Video 2021-03-26 at 4.57.31 PM.mp4')\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(100, 3))\n",
    "\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i],2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = [['test_image1','90%','TP'], ['test_image2', '100%','TP'], ['test_image3', '100%','TP'],['test_image4','53%','FP'],['test_image5','80%','TP']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,columns=['Image','confidence','TP or FP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['test_image1','90%',1,0,1,0,1,0.0666], ['test_image2', '100%',1,0,2,0,1,0.13], ['test_image3', '100%',1,0,3,0,1,0.2],['test_image4','53%',0,1,3,1,0.75,0.2],['test_image5','80%',1,0,4,1,0.8,0.26]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,columns=['Image','confidence','TP','FP','Acc TP','Acc FP','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>confidence</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>Acc TP</th>\n",
       "      <th>Acc FP</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_image1</td>\n",
       "      <td>90%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_image2</td>\n",
       "      <td>100%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_image3</td>\n",
       "      <td>100%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_image4</td>\n",
       "      <td>53%</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_image5</td>\n",
       "      <td>80%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.2600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image confidence  TP  FP  Acc TP  Acc FP  Precision  Recall\n",
       "0  test_image1        90%   1   0       1       0       1.00  0.0666\n",
       "1  test_image2       100%   1   0       2       0       1.00  0.1300\n",
       "2  test_image3       100%   1   0       3       0       1.00  0.2000\n",
       "3  test_image4        53%   0   1       3       1       0.75  0.2000\n",
       "4  test_image5        80%   1   0       4       1       0.80  0.2600"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'precision')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df['Recall'],df['Precision'])\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
